{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "su4Y1g-f8uEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "6ea7a9f0-e324-494b-e43a-86d3385fdd5d"
      },
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "import joblib\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D\n",
        "from keras.regularizers import l1\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTLfZ7OB-TDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce454805-7868-433a-c128-6c12fc4ec076"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYHnQG8PFoDE",
        "colab_type": "text"
      },
      "source": [
        "Importing Dataset of Twitter Reviews\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDrYsiIf8-bY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "28433680-9c6e-45e4-88c3-1d164105d341"
      },
      "source": [
        "twitter_reviews = pandas.read_csv(\"/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/IMDB Dataset.csv\")\n",
        "twitter_reviews.isnull().values.any()\n",
        "print(twitter_reviews.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnkPUh6kF1JW",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Of Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gTn426Q_1bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TAG_REMOVAL = re.compile(r'<[^>]+>')\n",
        "def tags_removal(txt):\n",
        "    return TAG_REMOVAL.sub('', txt)\n",
        "    \n",
        "def preprocess(sentence):\n",
        "    sentence_of_words = tags_removal(sentence)\n",
        "    sentence_of_words = re.sub('[^a-zA-Z]', ' ', sentence_of_words)\n",
        "    sentence_of_words = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', sentence_of_words)\n",
        "    sentence_of_words = re.sub(r'\\s+', ' ', sentence_of_words)\n",
        "    return sentence_of_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVchNCn1_5ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = twitter_reviews['sentiment']\n",
        "Y = numpy.array(list(map(lambda x: 1 if x == 'positive' else 0, Y)))\n",
        "sentences = list(twitter_reviews['review'])\n",
        "X = []  \n",
        "for sen in sentences:\n",
        "    X.append(preprocess(sen)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkGrYnYPAKTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0xXntTyAMDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxVQ0rlVAQc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabsize = 1\n",
        "vocabsize += len(tokenizer.word_index)\n",
        "maxlength = 100\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlength)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlength)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz42mdcTfFjK",
        "colab_type": "text"
      },
      "source": [
        "Using the GloVe precomputed Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muAFbTF3ASo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "glove_pretrained = open('/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "embeddings_dict = dict()\n",
        "\n",
        "for line in glove_pretrained:\n",
        "    sen = line.split()\n",
        "    word = sen[0]\n",
        "    vector = asarray(sen[1 : ], dtype='float32')\n",
        "    embeddings_dict[word] = vector\n",
        "glove_pretrained.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeiyIkHRFVvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_words = tokenizer.word_index.items()\n",
        "embedding_matrix = zeros((vocabsize, 100))\n",
        "for word, index in all_words:\n",
        "    embedding_vector = embeddings_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index]=embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htK9ljxla2SA",
        "colab_type": "text"
      },
      "source": [
        "MLP + TRAIN EMBEDDING\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-ffp0l8FWgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "e74adbe1-196a-430b-8371-f9317ed33ee2"
      },
      "source": [
        "model_mlp = Sequential()\n",
        "embedding_layer = Embedding(vocabsize, 100, input_length=maxlength)\n",
        "model_mlp.add(embedding_layer)\n",
        "model_mlp.add(Flatten())\n",
        "model_mlp.add(Dense(16, activation='sigmoid'))\n",
        "model_mlp.add(Dense(1, activation='sigmoid'))\n",
        "model_mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model_mlp.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 100)          9254700   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                160016    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 9,414,733\n",
            "Trainable params: 9,414,733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OFyKI1XFbpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e8b3ac7-972d-4a44-a089-7d4369ff85f7"
      },
      "source": [
        "history_mlp = model_mlp.fit(X_train, Y_train, batch_size=32000, epochs=100, verbose=1, validation_split=0.2)\n",
        "score = model_mlp.evaluate(X_test, Y_test, verbose=1)\n",
        "scoretrain = model_mlp.evaluate(X_train, Y_train, verbose=1)\n",
        "print('Train Accuracy:', scoretrain[1])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "32000/32000 [==============================] - 5s 143us/step - loss: 0.7151 - acc: 0.5012 - val_loss: 0.7114 - val_acc: 0.5000\n",
            "Epoch 2/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.7104 - acc: 0.5012 - val_loss: 0.7071 - val_acc: 0.5000\n",
            "Epoch 3/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.7058 - acc: 0.5012 - val_loss: 0.7027 - val_acc: 0.5000\n",
            "Epoch 4/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.7010 - acc: 0.5012 - val_loss: 0.6981 - val_acc: 0.5104\n",
            "Epoch 5/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6961 - acc: 0.5122 - val_loss: 0.6936 - val_acc: 0.5119\n",
            "Epoch 6/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6913 - acc: 0.5141 - val_loss: 0.6895 - val_acc: 0.5128\n",
            "Epoch 7/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6868 - acc: 0.5174 - val_loss: 0.6860 - val_acc: 0.5350\n",
            "Epoch 8/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6828 - acc: 0.5487 - val_loss: 0.6831 - val_acc: 0.6334\n",
            "Epoch 9/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6795 - acc: 0.6693 - val_loss: 0.6805 - val_acc: 0.6208\n",
            "Epoch 10/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6765 - acc: 0.6504 - val_loss: 0.6778 - val_acc: 0.5865\n",
            "Epoch 11/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6735 - acc: 0.6043 - val_loss: 0.6745 - val_acc: 0.5714\n",
            "Epoch 12/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6698 - acc: 0.5874 - val_loss: 0.6703 - val_acc: 0.5773\n",
            "Epoch 13/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6651 - acc: 0.5938 - val_loss: 0.6651 - val_acc: 0.5956\n",
            "Epoch 14/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6594 - acc: 0.6169 - val_loss: 0.6590 - val_acc: 0.6291\n",
            "Epoch 15/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6529 - acc: 0.6507 - val_loss: 0.6523 - val_acc: 0.6680\n",
            "Epoch 16/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6456 - acc: 0.6884 - val_loss: 0.6451 - val_acc: 0.7044\n",
            "Epoch 17/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6379 - acc: 0.7250 - val_loss: 0.6375 - val_acc: 0.7365\n",
            "Epoch 18/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6297 - acc: 0.7595 - val_loss: 0.6297 - val_acc: 0.7621\n",
            "Epoch 19/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6213 - acc: 0.7818 - val_loss: 0.6216 - val_acc: 0.7671\n",
            "Epoch 20/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6127 - acc: 0.7887 - val_loss: 0.6133 - val_acc: 0.7661\n",
            "Epoch 21/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6037 - acc: 0.7861 - val_loss: 0.6045 - val_acc: 0.7620\n",
            "Epoch 22/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5943 - acc: 0.7828 - val_loss: 0.5949 - val_acc: 0.7632\n",
            "Epoch 23/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5841 - acc: 0.7823 - val_loss: 0.5846 - val_acc: 0.7688\n",
            "Epoch 24/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5732 - acc: 0.7872 - val_loss: 0.5737 - val_acc: 0.7742\n",
            "Epoch 25/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5617 - acc: 0.7929 - val_loss: 0.5626 - val_acc: 0.7801\n",
            "Epoch 26/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5500 - acc: 0.7980 - val_loss: 0.5517 - val_acc: 0.7851\n",
            "Epoch 27/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5385 - acc: 0.8017 - val_loss: 0.5413 - val_acc: 0.7879\n",
            "Epoch 28/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5274 - acc: 0.8043 - val_loss: 0.5313 - val_acc: 0.7910\n",
            "Epoch 29/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5169 - acc: 0.8061 - val_loss: 0.5216 - val_acc: 0.7939\n",
            "Epoch 30/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5064 - acc: 0.8077 - val_loss: 0.5118 - val_acc: 0.7966\n",
            "Epoch 31/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4959 - acc: 0.8116 - val_loss: 0.5022 - val_acc: 0.8008\n",
            "Epoch 32/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4854 - acc: 0.8157 - val_loss: 0.4931 - val_acc: 0.8030\n",
            "Epoch 33/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4754 - acc: 0.8199 - val_loss: 0.4845 - val_acc: 0.8061\n",
            "Epoch 34/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4660 - acc: 0.8235 - val_loss: 0.4765 - val_acc: 0.8087\n",
            "Epoch 35/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4570 - acc: 0.8272 - val_loss: 0.4686 - val_acc: 0.8135\n",
            "Epoch 36/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4482 - acc: 0.8302 - val_loss: 0.4609 - val_acc: 0.8161\n",
            "Epoch 37/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4395 - acc: 0.8345 - val_loss: 0.4537 - val_acc: 0.8205\n",
            "Epoch 38/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4311 - acc: 0.8380 - val_loss: 0.4470 - val_acc: 0.8250\n",
            "Epoch 39/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4233 - acc: 0.8412 - val_loss: 0.4408 - val_acc: 0.8264\n",
            "Epoch 40/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4159 - acc: 0.8444 - val_loss: 0.4349 - val_acc: 0.8286\n",
            "Epoch 41/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4087 - acc: 0.8479 - val_loss: 0.4293 - val_acc: 0.8291\n",
            "Epoch 42/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4018 - acc: 0.8505 - val_loss: 0.4243 - val_acc: 0.8303\n",
            "Epoch 43/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3952 - acc: 0.8536 - val_loss: 0.4198 - val_acc: 0.8315\n",
            "Epoch 44/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3892 - acc: 0.8556 - val_loss: 0.4157 - val_acc: 0.8328\n",
            "Epoch 45/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3835 - acc: 0.8576 - val_loss: 0.4117 - val_acc: 0.8330\n",
            "Epoch 46/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3781 - acc: 0.8602 - val_loss: 0.4080 - val_acc: 0.8338\n",
            "Epoch 47/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3728 - acc: 0.8627 - val_loss: 0.4046 - val_acc: 0.8354\n",
            "Epoch 48/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3679 - acc: 0.8642 - val_loss: 0.4016 - val_acc: 0.8364\n",
            "Epoch 49/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3633 - acc: 0.8665 - val_loss: 0.3988 - val_acc: 0.8380\n",
            "Epoch 50/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3589 - acc: 0.8687 - val_loss: 0.3962 - val_acc: 0.8388\n",
            "Epoch 51/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3545 - acc: 0.8707 - val_loss: 0.3938 - val_acc: 0.8393\n",
            "Epoch 52/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3504 - acc: 0.8728 - val_loss: 0.3915 - val_acc: 0.8391\n",
            "Epoch 53/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3463 - acc: 0.8749 - val_loss: 0.3893 - val_acc: 0.8393\n",
            "Epoch 54/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3423 - acc: 0.8768 - val_loss: 0.3872 - val_acc: 0.8409\n",
            "Epoch 55/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3384 - acc: 0.8783 - val_loss: 0.3852 - val_acc: 0.8406\n",
            "Epoch 56/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3346 - acc: 0.8802 - val_loss: 0.3833 - val_acc: 0.8422\n",
            "Epoch 57/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3309 - acc: 0.8818 - val_loss: 0.3815 - val_acc: 0.8429\n",
            "Epoch 58/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3272 - acc: 0.8834 - val_loss: 0.3798 - val_acc: 0.8438\n",
            "Epoch 59/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3236 - acc: 0.8856 - val_loss: 0.3783 - val_acc: 0.8444\n",
            "Epoch 60/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3202 - acc: 0.8876 - val_loss: 0.3768 - val_acc: 0.8453\n",
            "Epoch 61/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3169 - acc: 0.8893 - val_loss: 0.3754 - val_acc: 0.8455\n",
            "Epoch 62/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3136 - acc: 0.8907 - val_loss: 0.3742 - val_acc: 0.8456\n",
            "Epoch 63/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3104 - acc: 0.8925 - val_loss: 0.3730 - val_acc: 0.8455\n",
            "Epoch 64/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3074 - acc: 0.8944 - val_loss: 0.3721 - val_acc: 0.8468\n",
            "Epoch 65/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3044 - acc: 0.8963 - val_loss: 0.3712 - val_acc: 0.8471\n",
            "Epoch 66/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3015 - acc: 0.8979 - val_loss: 0.3705 - val_acc: 0.8485\n",
            "Epoch 67/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2987 - acc: 0.8995 - val_loss: 0.3698 - val_acc: 0.8476\n",
            "Epoch 68/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2959 - acc: 0.9013 - val_loss: 0.3691 - val_acc: 0.8481\n",
            "Epoch 69/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2932 - acc: 0.9025 - val_loss: 0.3684 - val_acc: 0.8485\n",
            "Epoch 70/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2905 - acc: 0.9036 - val_loss: 0.3678 - val_acc: 0.8496\n",
            "Epoch 71/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2879 - acc: 0.9048 - val_loss: 0.3673 - val_acc: 0.8496\n",
            "Epoch 72/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2853 - acc: 0.9062 - val_loss: 0.3669 - val_acc: 0.8486\n",
            "Epoch 73/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2827 - acc: 0.9076 - val_loss: 0.3666 - val_acc: 0.8491\n",
            "Epoch 74/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2802 - acc: 0.9084 - val_loss: 0.3663 - val_acc: 0.8487\n",
            "Epoch 75/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2778 - acc: 0.9098 - val_loss: 0.3659 - val_acc: 0.8491\n",
            "Epoch 76/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2753 - acc: 0.9117 - val_loss: 0.3655 - val_acc: 0.8497\n",
            "Epoch 77/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2729 - acc: 0.9128 - val_loss: 0.3652 - val_acc: 0.8500\n",
            "Epoch 78/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2706 - acc: 0.9143 - val_loss: 0.3650 - val_acc: 0.8494\n",
            "Epoch 79/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2682 - acc: 0.9155 - val_loss: 0.3649 - val_acc: 0.8497\n",
            "Epoch 80/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2659 - acc: 0.9171 - val_loss: 0.3647 - val_acc: 0.8501\n",
            "Epoch 81/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2637 - acc: 0.9187 - val_loss: 0.3645 - val_acc: 0.8497\n",
            "Epoch 82/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2614 - acc: 0.9199 - val_loss: 0.3642 - val_acc: 0.8497\n",
            "Epoch 83/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2592 - acc: 0.9212 - val_loss: 0.3641 - val_acc: 0.8491\n",
            "Epoch 84/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2570 - acc: 0.9228 - val_loss: 0.3639 - val_acc: 0.8491\n",
            "Epoch 85/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2548 - acc: 0.9241 - val_loss: 0.3638 - val_acc: 0.8489\n",
            "Epoch 86/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2526 - acc: 0.9251 - val_loss: 0.3637 - val_acc: 0.8491\n",
            "Epoch 87/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2504 - acc: 0.9263 - val_loss: 0.3636 - val_acc: 0.8494\n",
            "Epoch 88/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2483 - acc: 0.9275 - val_loss: 0.3634 - val_acc: 0.8493\n",
            "Epoch 89/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2461 - acc: 0.9285 - val_loss: 0.3634 - val_acc: 0.8495\n",
            "Epoch 90/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2440 - acc: 0.9295 - val_loss: 0.3634 - val_acc: 0.8499\n",
            "Epoch 91/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2419 - acc: 0.9307 - val_loss: 0.3634 - val_acc: 0.8491\n",
            "Epoch 92/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2398 - acc: 0.9318 - val_loss: 0.3634 - val_acc: 0.8496\n",
            "Epoch 93/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2377 - acc: 0.9328 - val_loss: 0.3634 - val_acc: 0.8508\n",
            "Epoch 94/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2356 - acc: 0.9339 - val_loss: 0.3634 - val_acc: 0.8503\n",
            "Epoch 95/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2335 - acc: 0.9351 - val_loss: 0.3635 - val_acc: 0.8499\n",
            "Epoch 96/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2314 - acc: 0.9364 - val_loss: 0.3636 - val_acc: 0.8501\n",
            "Epoch 97/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2294 - acc: 0.9379 - val_loss: 0.3638 - val_acc: 0.8500\n",
            "Epoch 98/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2273 - acc: 0.9392 - val_loss: 0.3639 - val_acc: 0.8499\n",
            "Epoch 99/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2252 - acc: 0.9401 - val_loss: 0.3640 - val_acc: 0.8494\n",
            "Epoch 100/100\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.2231 - acc: 0.9412 - val_loss: 0.3642 - val_acc: 0.8493\n",
            "10000/10000 [==============================] - 0s 40us/step\n",
            "40000/40000 [==============================] - 2s 38us/step\n",
            "Train Accuracy: 0.923775\n",
            "Test Accuracy: 0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1F8VCCna_Lb",
        "colab_type": "text"
      },
      "source": [
        "MLP + GLOVE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xubz6Fda9vi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "a2168876-e1cb-4e7d-afd2-771af4d57eb6"
      },
      "source": [
        "model_mlp_glove = Sequential()\n",
        "embedding_layer = Embedding(vocabsize, 100, weights=[embedding_matrix], input_length=maxlength, trainable=False)\n",
        "model_mlp_glove.add(embedding_layer)\n",
        "model_mlp_glove.add(Flatten())\n",
        "model_mlp_glove.add(Dense(16, activation='sigmoid'))\n",
        "model_mlp_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_mlp_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model_mlp_glove.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 100)          9254700   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                160016    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 9,414,733\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 9,254,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SvC7REcXLDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d12bfcb-e2a7-4f6a-f177-7ea52ca0ccbd"
      },
      "source": [
        "history_mlp_glove = model_mlp_glove.fit(X_train, Y_train, batch_size=32000, epochs=250, verbose=1, validation_split=0.2)\n",
        "score = model_mlp_glove.evaluate(X_test, Y_test, verbose=1)\n",
        "scoretrain = model_mlp_glove.evaluate(X_train, Y_train, verbose=1)\n",
        "print('Train Accuracy:', scoretrain[1])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/250\n",
            "32000/32000 [==============================] - 0s 8us/step - loss: 0.6964 - acc: 0.5041 - val_loss: 0.7436 - val_acc: 0.5005\n",
            "Epoch 2/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.7424 - acc: 0.4988 - val_loss: 0.7386 - val_acc: 0.5038\n",
            "Epoch 3/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.7360 - acc: 0.5044 - val_loss: 0.7071 - val_acc: 0.5102\n",
            "Epoch 4/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.7043 - acc: 0.5117 - val_loss: 0.6656 - val_acc: 0.6327\n",
            "Epoch 5/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6629 - acc: 0.6364 - val_loss: 0.6865 - val_acc: 0.5130\n",
            "Epoch 6/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6842 - acc: 0.5138 - val_loss: 0.6851 - val_acc: 0.5145\n",
            "Epoch 7/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6827 - acc: 0.5142 - val_loss: 0.6642 - val_acc: 0.5864\n",
            "Epoch 8/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6614 - acc: 0.5924 - val_loss: 0.6566 - val_acc: 0.6476\n",
            "Epoch 9/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6534 - acc: 0.6575 - val_loss: 0.6625 - val_acc: 0.5918\n",
            "Epoch 10/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6591 - acc: 0.6013 - val_loss: 0.6651 - val_acc: 0.5755\n",
            "Epoch 11/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6616 - acc: 0.5850 - val_loss: 0.6575 - val_acc: 0.6031\n",
            "Epoch 12/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6537 - acc: 0.6112 - val_loss: 0.6457 - val_acc: 0.6543\n",
            "Epoch 13/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6416 - acc: 0.6608 - val_loss: 0.6395 - val_acc: 0.6662\n",
            "Epoch 14/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6352 - acc: 0.6712 - val_loss: 0.6404 - val_acc: 0.6314\n",
            "Epoch 15/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6359 - acc: 0.6433 - val_loss: 0.6386 - val_acc: 0.6264\n",
            "Epoch 16/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6337 - acc: 0.6369 - val_loss: 0.6283 - val_acc: 0.6564\n",
            "Epoch 17/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.6228 - acc: 0.6648 - val_loss: 0.6199 - val_acc: 0.6808\n",
            "Epoch 18/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6137 - acc: 0.6832 - val_loss: 0.6203 - val_acc: 0.6702\n",
            "Epoch 19/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6137 - acc: 0.6782 - val_loss: 0.6187 - val_acc: 0.6699\n",
            "Epoch 20/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6118 - acc: 0.6766 - val_loss: 0.6117 - val_acc: 0.6850\n",
            "Epoch 21/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6045 - acc: 0.6883 - val_loss: 0.6088 - val_acc: 0.6841\n",
            "Epoch 22/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6015 - acc: 0.6896 - val_loss: 0.6098 - val_acc: 0.6754\n",
            "Epoch 23/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.6024 - acc: 0.6846 - val_loss: 0.6061 - val_acc: 0.6852\n",
            "Epoch 24/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5984 - acc: 0.6898 - val_loss: 0.6005 - val_acc: 0.6926\n",
            "Epoch 25/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5923 - acc: 0.6979 - val_loss: 0.5995 - val_acc: 0.6920\n",
            "Epoch 26/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5909 - acc: 0.6986 - val_loss: 0.5986 - val_acc: 0.6888\n",
            "Epoch 27/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5895 - acc: 0.6974 - val_loss: 0.5930 - val_acc: 0.6954\n",
            "Epoch 28/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5833 - acc: 0.7036 - val_loss: 0.5892 - val_acc: 0.7020\n",
            "Epoch 29/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5789 - acc: 0.7088 - val_loss: 0.5890 - val_acc: 0.6995\n",
            "Epoch 30/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5781 - acc: 0.7087 - val_loss: 0.5858 - val_acc: 0.7025\n",
            "Epoch 31/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5741 - acc: 0.7136 - val_loss: 0.5816 - val_acc: 0.7076\n",
            "Epoch 32/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5691 - acc: 0.7186 - val_loss: 0.5811 - val_acc: 0.7057\n",
            "Epoch 33/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5679 - acc: 0.7193 - val_loss: 0.5798 - val_acc: 0.7064\n",
            "Epoch 34/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5659 - acc: 0.7206 - val_loss: 0.5761 - val_acc: 0.7136\n",
            "Epoch 35/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5616 - acc: 0.7285 - val_loss: 0.5742 - val_acc: 0.7155\n",
            "Epoch 36/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5591 - acc: 0.7312 - val_loss: 0.5730 - val_acc: 0.7145\n",
            "Epoch 37/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5572 - acc: 0.7318 - val_loss: 0.5694 - val_acc: 0.7186\n",
            "Epoch 38/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5527 - acc: 0.7369 - val_loss: 0.5667 - val_acc: 0.7215\n",
            "Epoch 39/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5490 - acc: 0.7402 - val_loss: 0.5653 - val_acc: 0.7197\n",
            "Epoch 40/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5468 - acc: 0.7401 - val_loss: 0.5624 - val_acc: 0.7241\n",
            "Epoch 41/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5430 - acc: 0.7439 - val_loss: 0.5603 - val_acc: 0.7249\n",
            "Epoch 42/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5402 - acc: 0.7465 - val_loss: 0.5596 - val_acc: 0.7264\n",
            "Epoch 43/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5389 - acc: 0.7469 - val_loss: 0.5572 - val_acc: 0.7290\n",
            "Epoch 44/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5358 - acc: 0.7511 - val_loss: 0.5556 - val_acc: 0.7297\n",
            "Epoch 45/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5335 - acc: 0.7526 - val_loss: 0.5546 - val_acc: 0.7304\n",
            "Epoch 46/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5318 - acc: 0.7528 - val_loss: 0.5523 - val_acc: 0.7331\n",
            "Epoch 47/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5287 - acc: 0.7580 - val_loss: 0.5512 - val_acc: 0.7352\n",
            "Epoch 48/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5269 - acc: 0.7602 - val_loss: 0.5497 - val_acc: 0.7372\n",
            "Epoch 49/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5245 - acc: 0.7620 - val_loss: 0.5481 - val_acc: 0.7365\n",
            "Epoch 50/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5219 - acc: 0.7638 - val_loss: 0.5473 - val_acc: 0.7358\n",
            "Epoch 51/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5201 - acc: 0.7645 - val_loss: 0.5457 - val_acc: 0.7379\n",
            "Epoch 52/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5175 - acc: 0.7671 - val_loss: 0.5448 - val_acc: 0.7381\n",
            "Epoch 53/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5157 - acc: 0.7684 - val_loss: 0.5439 - val_acc: 0.7380\n",
            "Epoch 54/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5137 - acc: 0.7700 - val_loss: 0.5426 - val_acc: 0.7387\n",
            "Epoch 55/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5115 - acc: 0.7727 - val_loss: 0.5418 - val_acc: 0.7391\n",
            "Epoch 56/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5099 - acc: 0.7728 - val_loss: 0.5405 - val_acc: 0.7381\n",
            "Epoch 57/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5077 - acc: 0.7751 - val_loss: 0.5395 - val_acc: 0.7401\n",
            "Epoch 58/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5058 - acc: 0.7757 - val_loss: 0.5384 - val_acc: 0.7419\n",
            "Epoch 59/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5040 - acc: 0.7767 - val_loss: 0.5371 - val_acc: 0.7409\n",
            "Epoch 60/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.5019 - acc: 0.7775 - val_loss: 0.5362 - val_acc: 0.7401\n",
            "Epoch 61/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.5003 - acc: 0.7787 - val_loss: 0.5351 - val_acc: 0.7418\n",
            "Epoch 62/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.7795 - val_loss: 0.5343 - val_acc: 0.7446\n",
            "Epoch 63/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4967 - acc: 0.7807 - val_loss: 0.5334 - val_acc: 0.7450\n",
            "Epoch 64/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4950 - acc: 0.7819 - val_loss: 0.5325 - val_acc: 0.7461\n",
            "Epoch 65/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4931 - acc: 0.7828 - val_loss: 0.5317 - val_acc: 0.7456\n",
            "Epoch 66/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4915 - acc: 0.7841 - val_loss: 0.5309 - val_acc: 0.7464\n",
            "Epoch 67/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4898 - acc: 0.7851 - val_loss: 0.5304 - val_acc: 0.7455\n",
            "Epoch 68/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4883 - acc: 0.7851 - val_loss: 0.5296 - val_acc: 0.7455\n",
            "Epoch 69/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4867 - acc: 0.7868 - val_loss: 0.5288 - val_acc: 0.7458\n",
            "Epoch 70/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 0.7880 - val_loss: 0.5281 - val_acc: 0.7460\n",
            "Epoch 71/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4836 - acc: 0.7887 - val_loss: 0.5274 - val_acc: 0.7462\n",
            "Epoch 72/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4820 - acc: 0.7888 - val_loss: 0.5268 - val_acc: 0.7459\n",
            "Epoch 73/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.7893 - val_loss: 0.5260 - val_acc: 0.7471\n",
            "Epoch 74/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4790 - acc: 0.7906 - val_loss: 0.5254 - val_acc: 0.7475\n",
            "Epoch 75/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4776 - acc: 0.7918 - val_loss: 0.5247 - val_acc: 0.7473\n",
            "Epoch 76/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4760 - acc: 0.7926 - val_loss: 0.5241 - val_acc: 0.7467\n",
            "Epoch 77/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4744 - acc: 0.7931 - val_loss: 0.5233 - val_acc: 0.7476\n",
            "Epoch 78/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4728 - acc: 0.7939 - val_loss: 0.5226 - val_acc: 0.7467\n",
            "Epoch 79/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4712 - acc: 0.7947 - val_loss: 0.5219 - val_acc: 0.7464\n",
            "Epoch 80/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4696 - acc: 0.7955 - val_loss: 0.5212 - val_acc: 0.7471\n",
            "Epoch 81/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4680 - acc: 0.7960 - val_loss: 0.5207 - val_acc: 0.7480\n",
            "Epoch 82/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4666 - acc: 0.7962 - val_loss: 0.5202 - val_acc: 0.7479\n",
            "Epoch 83/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4652 - acc: 0.7970 - val_loss: 0.5198 - val_acc: 0.7481\n",
            "Epoch 84/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4640 - acc: 0.7981 - val_loss: 0.5195 - val_acc: 0.7484\n",
            "Epoch 85/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4628 - acc: 0.7984 - val_loss: 0.5193 - val_acc: 0.7496\n",
            "Epoch 86/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4617 - acc: 0.7989 - val_loss: 0.5191 - val_acc: 0.7484\n",
            "Epoch 87/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4606 - acc: 0.7999 - val_loss: 0.5189 - val_acc: 0.7485\n",
            "Epoch 88/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4594 - acc: 0.8005 - val_loss: 0.5186 - val_acc: 0.7479\n",
            "Epoch 89/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.8012 - val_loss: 0.5184 - val_acc: 0.7483\n",
            "Epoch 90/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4570 - acc: 0.8028 - val_loss: 0.5181 - val_acc: 0.7481\n",
            "Epoch 91/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4557 - acc: 0.8028 - val_loss: 0.5178 - val_acc: 0.7483\n",
            "Epoch 92/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4544 - acc: 0.8038 - val_loss: 0.5176 - val_acc: 0.7484\n",
            "Epoch 93/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4531 - acc: 0.8045 - val_loss: 0.5174 - val_acc: 0.7486\n",
            "Epoch 94/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4519 - acc: 0.8052 - val_loss: 0.5172 - val_acc: 0.7476\n",
            "Epoch 95/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4507 - acc: 0.8060 - val_loss: 0.5171 - val_acc: 0.7484\n",
            "Epoch 96/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4496 - acc: 0.8066 - val_loss: 0.5170 - val_acc: 0.7473\n",
            "Epoch 97/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4486 - acc: 0.8069 - val_loss: 0.5168 - val_acc: 0.7479\n",
            "Epoch 98/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4475 - acc: 0.8077 - val_loss: 0.5167 - val_acc: 0.7479\n",
            "Epoch 99/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4465 - acc: 0.8087 - val_loss: 0.5165 - val_acc: 0.7477\n",
            "Epoch 100/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.8092 - val_loss: 0.5163 - val_acc: 0.7483\n",
            "Epoch 101/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4442 - acc: 0.8098 - val_loss: 0.5161 - val_acc: 0.7480\n",
            "Epoch 102/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4431 - acc: 0.8104 - val_loss: 0.5159 - val_acc: 0.7483\n",
            "Epoch 103/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4420 - acc: 0.8105 - val_loss: 0.5157 - val_acc: 0.7484\n",
            "Epoch 104/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4409 - acc: 0.8110 - val_loss: 0.5156 - val_acc: 0.7486\n",
            "Epoch 105/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4399 - acc: 0.8119 - val_loss: 0.5155 - val_acc: 0.7489\n",
            "Epoch 106/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4389 - acc: 0.8126 - val_loss: 0.5154 - val_acc: 0.7491\n",
            "Epoch 107/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4379 - acc: 0.8129 - val_loss: 0.5154 - val_acc: 0.7481\n",
            "Epoch 108/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4369 - acc: 0.8136 - val_loss: 0.5153 - val_acc: 0.7479\n",
            "Epoch 109/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4359 - acc: 0.8144 - val_loss: 0.5152 - val_acc: 0.7481\n",
            "Epoch 110/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4349 - acc: 0.8148 - val_loss: 0.5152 - val_acc: 0.7475\n",
            "Epoch 111/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4338 - acc: 0.8155 - val_loss: 0.5152 - val_acc: 0.7477\n",
            "Epoch 112/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4328 - acc: 0.8156 - val_loss: 0.5152 - val_acc: 0.7475\n",
            "Epoch 113/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4319 - acc: 0.8163 - val_loss: 0.5152 - val_acc: 0.7470\n",
            "Epoch 114/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4309 - acc: 0.8170 - val_loss: 0.5152 - val_acc: 0.7464\n",
            "Epoch 115/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4300 - acc: 0.8177 - val_loss: 0.5152 - val_acc: 0.7466\n",
            "Epoch 116/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4290 - acc: 0.8183 - val_loss: 0.5152 - val_acc: 0.7467\n",
            "Epoch 117/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4281 - acc: 0.8187 - val_loss: 0.5152 - val_acc: 0.7474\n",
            "Epoch 118/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4271 - acc: 0.8190 - val_loss: 0.5152 - val_acc: 0.7476\n",
            "Epoch 119/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4262 - acc: 0.8194 - val_loss: 0.5152 - val_acc: 0.7471\n",
            "Epoch 120/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4253 - acc: 0.8200 - val_loss: 0.5152 - val_acc: 0.7474\n",
            "Epoch 121/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4244 - acc: 0.8207 - val_loss: 0.5152 - val_acc: 0.7466\n",
            "Epoch 122/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4235 - acc: 0.8212 - val_loss: 0.5152 - val_acc: 0.7469\n",
            "Epoch 123/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4226 - acc: 0.8214 - val_loss: 0.5152 - val_acc: 0.7467\n",
            "Epoch 124/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4217 - acc: 0.8221 - val_loss: 0.5153 - val_acc: 0.7466\n",
            "Epoch 125/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4208 - acc: 0.8226 - val_loss: 0.5153 - val_acc: 0.7469\n",
            "Epoch 126/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4199 - acc: 0.8233 - val_loss: 0.5154 - val_acc: 0.7471\n",
            "Epoch 127/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4190 - acc: 0.8240 - val_loss: 0.5154 - val_acc: 0.7474\n",
            "Epoch 128/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4181 - acc: 0.8244 - val_loss: 0.5155 - val_acc: 0.7474\n",
            "Epoch 129/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4172 - acc: 0.8250 - val_loss: 0.5155 - val_acc: 0.7477\n",
            "Epoch 130/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4164 - acc: 0.8256 - val_loss: 0.5156 - val_acc: 0.7484\n",
            "Epoch 131/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4155 - acc: 0.8258 - val_loss: 0.5156 - val_acc: 0.7485\n",
            "Epoch 132/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4146 - acc: 0.8264 - val_loss: 0.5157 - val_acc: 0.7486\n",
            "Epoch 133/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4138 - acc: 0.8269 - val_loss: 0.5157 - val_acc: 0.7479\n",
            "Epoch 134/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4129 - acc: 0.8273 - val_loss: 0.5158 - val_acc: 0.7481\n",
            "Epoch 135/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4121 - acc: 0.8279 - val_loss: 0.5159 - val_acc: 0.7485\n",
            "Epoch 136/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4112 - acc: 0.8283 - val_loss: 0.5160 - val_acc: 0.7483\n",
            "Epoch 137/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4104 - acc: 0.8287 - val_loss: 0.5160 - val_acc: 0.7485\n",
            "Epoch 138/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4095 - acc: 0.8291 - val_loss: 0.5161 - val_acc: 0.7480\n",
            "Epoch 139/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4087 - acc: 0.8294 - val_loss: 0.5162 - val_acc: 0.7485\n",
            "Epoch 140/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4079 - acc: 0.8296 - val_loss: 0.5163 - val_acc: 0.7491\n",
            "Epoch 141/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4070 - acc: 0.8303 - val_loss: 0.5164 - val_acc: 0.7483\n",
            "Epoch 142/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4062 - acc: 0.8306 - val_loss: 0.5165 - val_acc: 0.7484\n",
            "Epoch 143/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4054 - acc: 0.8310 - val_loss: 0.5166 - val_acc: 0.7483\n",
            "Epoch 144/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4046 - acc: 0.8319 - val_loss: 0.5167 - val_acc: 0.7484\n",
            "Epoch 145/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4038 - acc: 0.8322 - val_loss: 0.5168 - val_acc: 0.7485\n",
            "Epoch 146/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4029 - acc: 0.8327 - val_loss: 0.5169 - val_acc: 0.7484\n",
            "Epoch 147/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.4021 - acc: 0.8330 - val_loss: 0.5171 - val_acc: 0.7479\n",
            "Epoch 148/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4013 - acc: 0.8334 - val_loss: 0.5172 - val_acc: 0.7477\n",
            "Epoch 149/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.4005 - acc: 0.8337 - val_loss: 0.5173 - val_acc: 0.7477\n",
            "Epoch 150/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3998 - acc: 0.8341 - val_loss: 0.5174 - val_acc: 0.7481\n",
            "Epoch 151/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3990 - acc: 0.8347 - val_loss: 0.5176 - val_acc: 0.7484\n",
            "Epoch 152/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3981 - acc: 0.8349 - val_loss: 0.5178 - val_acc: 0.7489\n",
            "Epoch 153/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3973 - acc: 0.8352 - val_loss: 0.5179 - val_acc: 0.7476\n",
            "Epoch 154/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3966 - acc: 0.8357 - val_loss: 0.5181 - val_acc: 0.7484\n",
            "Epoch 155/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3958 - acc: 0.8358 - val_loss: 0.5182 - val_acc: 0.7480\n",
            "Epoch 156/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3950 - acc: 0.8363 - val_loss: 0.5184 - val_acc: 0.7486\n",
            "Epoch 157/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3942 - acc: 0.8367 - val_loss: 0.5186 - val_acc: 0.7480\n",
            "Epoch 158/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3935 - acc: 0.8373 - val_loss: 0.5187 - val_acc: 0.7479\n",
            "Epoch 159/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3927 - acc: 0.8376 - val_loss: 0.5189 - val_acc: 0.7469\n",
            "Epoch 160/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3919 - acc: 0.8380 - val_loss: 0.5191 - val_acc: 0.7469\n",
            "Epoch 161/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3911 - acc: 0.8383 - val_loss: 0.5192 - val_acc: 0.7473\n",
            "Epoch 162/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3904 - acc: 0.8388 - val_loss: 0.5194 - val_acc: 0.7461\n",
            "Epoch 163/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3896 - acc: 0.8390 - val_loss: 0.5196 - val_acc: 0.7467\n",
            "Epoch 164/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3889 - acc: 0.8395 - val_loss: 0.5197 - val_acc: 0.7462\n",
            "Epoch 165/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3881 - acc: 0.8398 - val_loss: 0.5199 - val_acc: 0.7462\n",
            "Epoch 166/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3873 - acc: 0.8404 - val_loss: 0.5201 - val_acc: 0.7465\n",
            "Epoch 167/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3866 - acc: 0.8409 - val_loss: 0.5202 - val_acc: 0.7461\n",
            "Epoch 168/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3859 - acc: 0.8409 - val_loss: 0.5204 - val_acc: 0.7462\n",
            "Epoch 169/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3851 - acc: 0.8417 - val_loss: 0.5206 - val_acc: 0.7459\n",
            "Epoch 170/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3843 - acc: 0.8419 - val_loss: 0.5207 - val_acc: 0.7458\n",
            "Epoch 171/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3836 - acc: 0.8423 - val_loss: 0.5209 - val_acc: 0.7462\n",
            "Epoch 172/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3829 - acc: 0.8428 - val_loss: 0.5211 - val_acc: 0.7464\n",
            "Epoch 173/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3821 - acc: 0.8430 - val_loss: 0.5213 - val_acc: 0.7470\n",
            "Epoch 174/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3814 - acc: 0.8433 - val_loss: 0.5215 - val_acc: 0.7461\n",
            "Epoch 175/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3807 - acc: 0.8437 - val_loss: 0.5217 - val_acc: 0.7465\n",
            "Epoch 176/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3799 - acc: 0.8443 - val_loss: 0.5219 - val_acc: 0.7467\n",
            "Epoch 177/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3792 - acc: 0.8444 - val_loss: 0.5221 - val_acc: 0.7473\n",
            "Epoch 178/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3784 - acc: 0.8449 - val_loss: 0.5222 - val_acc: 0.7474\n",
            "Epoch 179/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3777 - acc: 0.8453 - val_loss: 0.5224 - val_acc: 0.7471\n",
            "Epoch 180/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3770 - acc: 0.8457 - val_loss: 0.5226 - val_acc: 0.7474\n",
            "Epoch 181/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3763 - acc: 0.8462 - val_loss: 0.5228 - val_acc: 0.7469\n",
            "Epoch 182/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3755 - acc: 0.8459 - val_loss: 0.5230 - val_acc: 0.7476\n",
            "Epoch 183/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3748 - acc: 0.8469 - val_loss: 0.5233 - val_acc: 0.7466\n",
            "Epoch 184/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3741 - acc: 0.8465 - val_loss: 0.5234 - val_acc: 0.7466\n",
            "Epoch 185/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3734 - acc: 0.8475 - val_loss: 0.5237 - val_acc: 0.7464\n",
            "Epoch 186/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3727 - acc: 0.8472 - val_loss: 0.5238 - val_acc: 0.7465\n",
            "Epoch 187/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3720 - acc: 0.8482 - val_loss: 0.5241 - val_acc: 0.7465\n",
            "Epoch 188/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3713 - acc: 0.8482 - val_loss: 0.5242 - val_acc: 0.7469\n",
            "Epoch 189/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3705 - acc: 0.8490 - val_loss: 0.5245 - val_acc: 0.7467\n",
            "Epoch 190/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3698 - acc: 0.8489 - val_loss: 0.5246 - val_acc: 0.7465\n",
            "Epoch 191/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3691 - acc: 0.8497 - val_loss: 0.5248 - val_acc: 0.7461\n",
            "Epoch 192/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3684 - acc: 0.8497 - val_loss: 0.5251 - val_acc: 0.7461\n",
            "Epoch 193/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3677 - acc: 0.8500 - val_loss: 0.5253 - val_acc: 0.7466\n",
            "Epoch 194/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3670 - acc: 0.8510 - val_loss: 0.5255 - val_acc: 0.7466\n",
            "Epoch 195/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3663 - acc: 0.8508 - val_loss: 0.5257 - val_acc: 0.7464\n",
            "Epoch 196/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3656 - acc: 0.8515 - val_loss: 0.5259 - val_acc: 0.7470\n",
            "Epoch 197/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3649 - acc: 0.8517 - val_loss: 0.5261 - val_acc: 0.7460\n",
            "Epoch 198/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3642 - acc: 0.8522 - val_loss: 0.5264 - val_acc: 0.7467\n",
            "Epoch 199/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3635 - acc: 0.8522 - val_loss: 0.5266 - val_acc: 0.7454\n",
            "Epoch 200/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3628 - acc: 0.8530 - val_loss: 0.5268 - val_acc: 0.7456\n",
            "Epoch 201/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3621 - acc: 0.8534 - val_loss: 0.5270 - val_acc: 0.7458\n",
            "Epoch 202/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3614 - acc: 0.8534 - val_loss: 0.5272 - val_acc: 0.7455\n",
            "Epoch 203/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3607 - acc: 0.8540 - val_loss: 0.5274 - val_acc: 0.7462\n",
            "Epoch 204/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3599 - acc: 0.8541 - val_loss: 0.5277 - val_acc: 0.7456\n",
            "Epoch 205/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3592 - acc: 0.8547 - val_loss: 0.5279 - val_acc: 0.7454\n",
            "Epoch 206/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3585 - acc: 0.8549 - val_loss: 0.5281 - val_acc: 0.7456\n",
            "Epoch 207/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3578 - acc: 0.8553 - val_loss: 0.5283 - val_acc: 0.7450\n",
            "Epoch 208/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3572 - acc: 0.8555 - val_loss: 0.5285 - val_acc: 0.7456\n",
            "Epoch 209/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3565 - acc: 0.8558 - val_loss: 0.5288 - val_acc: 0.7448\n",
            "Epoch 210/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3558 - acc: 0.8563 - val_loss: 0.5290 - val_acc: 0.7454\n",
            "Epoch 211/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3551 - acc: 0.8567 - val_loss: 0.5293 - val_acc: 0.7449\n",
            "Epoch 212/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3545 - acc: 0.8574 - val_loss: 0.5295 - val_acc: 0.7452\n",
            "Epoch 213/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3538 - acc: 0.8576 - val_loss: 0.5298 - val_acc: 0.7458\n",
            "Epoch 214/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3532 - acc: 0.8577 - val_loss: 0.5301 - val_acc: 0.7455\n",
            "Epoch 215/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3526 - acc: 0.8582 - val_loss: 0.5304 - val_acc: 0.7458\n",
            "Epoch 216/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3519 - acc: 0.8584 - val_loss: 0.5306 - val_acc: 0.7455\n",
            "Epoch 217/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3512 - acc: 0.8588 - val_loss: 0.5308 - val_acc: 0.7462\n",
            "Epoch 218/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3505 - acc: 0.8594 - val_loss: 0.5309 - val_acc: 0.7450\n",
            "Epoch 219/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3498 - acc: 0.8594 - val_loss: 0.5311 - val_acc: 0.7444\n",
            "Epoch 220/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3490 - acc: 0.8597 - val_loss: 0.5313 - val_acc: 0.7450\n",
            "Epoch 221/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3482 - acc: 0.8606 - val_loss: 0.5315 - val_acc: 0.7437\n",
            "Epoch 222/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3475 - acc: 0.8607 - val_loss: 0.5317 - val_acc: 0.7444\n",
            "Epoch 223/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3468 - acc: 0.8608 - val_loss: 0.5320 - val_acc: 0.7450\n",
            "Epoch 224/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3462 - acc: 0.8614 - val_loss: 0.5322 - val_acc: 0.7439\n",
            "Epoch 225/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3455 - acc: 0.8620 - val_loss: 0.5325 - val_acc: 0.7444\n",
            "Epoch 226/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3449 - acc: 0.8618 - val_loss: 0.5328 - val_acc: 0.7458\n",
            "Epoch 227/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3443 - acc: 0.8630 - val_loss: 0.5330 - val_acc: 0.7439\n",
            "Epoch 228/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3436 - acc: 0.8626 - val_loss: 0.5333 - val_acc: 0.7445\n",
            "Epoch 229/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3430 - acc: 0.8636 - val_loss: 0.5336 - val_acc: 0.7441\n",
            "Epoch 230/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3424 - acc: 0.8631 - val_loss: 0.5338 - val_acc: 0.7442\n",
            "Epoch 231/250\n",
            "32000/32000 [==============================] - 0s 2us/step - loss: 0.3417 - acc: 0.8641 - val_loss: 0.5341 - val_acc: 0.7446\n",
            "Epoch 232/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3410 - acc: 0.8640 - val_loss: 0.5343 - val_acc: 0.7441\n",
            "Epoch 233/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3404 - acc: 0.8649 - val_loss: 0.5345 - val_acc: 0.7444\n",
            "Epoch 234/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3397 - acc: 0.8646 - val_loss: 0.5347 - val_acc: 0.7446\n",
            "Epoch 235/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3389 - acc: 0.8656 - val_loss: 0.5349 - val_acc: 0.7441\n",
            "Epoch 236/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3382 - acc: 0.8654 - val_loss: 0.5351 - val_acc: 0.7442\n",
            "Epoch 237/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3375 - acc: 0.8669 - val_loss: 0.5353 - val_acc: 0.7448\n",
            "Epoch 238/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3368 - acc: 0.8665 - val_loss: 0.5355 - val_acc: 0.7444\n",
            "Epoch 239/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3361 - acc: 0.8679 - val_loss: 0.5357 - val_acc: 0.7444\n",
            "Epoch 240/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3354 - acc: 0.8677 - val_loss: 0.5359 - val_acc: 0.7444\n",
            "Epoch 241/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3347 - acc: 0.8685 - val_loss: 0.5362 - val_acc: 0.7449\n",
            "Epoch 242/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3340 - acc: 0.8685 - val_loss: 0.5364 - val_acc: 0.7449\n",
            "Epoch 243/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3333 - acc: 0.8694 - val_loss: 0.5366 - val_acc: 0.7449\n",
            "Epoch 244/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3326 - acc: 0.8695 - val_loss: 0.5369 - val_acc: 0.7451\n",
            "Epoch 245/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3319 - acc: 0.8700 - val_loss: 0.5371 - val_acc: 0.7449\n",
            "Epoch 246/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3313 - acc: 0.8702 - val_loss: 0.5373 - val_acc: 0.7454\n",
            "Epoch 247/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3306 - acc: 0.8709 - val_loss: 0.5376 - val_acc: 0.7444\n",
            "Epoch 248/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3299 - acc: 0.8709 - val_loss: 0.5378 - val_acc: 0.7452\n",
            "Epoch 249/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3292 - acc: 0.8718 - val_loss: 0.5381 - val_acc: 0.7441\n",
            "Epoch 250/250\n",
            "32000/32000 [==============================] - 0s 1us/step - loss: 0.3286 - acc: 0.8719 - val_loss: 0.5383 - val_acc: 0.7449\n",
            "10000/10000 [==============================] - 0s 39us/step\n",
            "40000/40000 [==============================] - 2s 39us/step\n",
            "Train Accuracy: 0.84715\n",
            "Test Accuracy: 0.7392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjTZZew3hkO6",
        "colab_type": "text"
      },
      "source": [
        "CNN + Trainable Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaHJ4amNY2uo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "d7caccaf-1fe2-4a96-a185-88096c67ee69"
      },
      "source": [
        "model_cnn = Sequential()\n",
        "embedding_layer = Embedding(vocabsize, 100, input_length=maxlength)\n",
        "model_cnn.add(embedding_layer)\n",
        "model_cnn.add(Conv1D(512, 5, activation='relu'))\n",
        "model_cnn.add(GlobalMaxPooling1D())\n",
        "model_cnn.add(Dense(16, activation='sigmoid'))\n",
        "model_cnn.add(Dense(1, activation='sigmoid'))\n",
        "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model_cnn.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 100, 100)          9254700   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 96, 512)           256512    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 16)                8208      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 9,519,437\n",
            "Trainable params: 9,519,437\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POyEQM5BX2VE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8070ffdd-fc43-4e8e-d859-395e4dc63e47"
      },
      "source": [
        "history_cnn = model_cnn.fit(X_train, Y_train, batch_size=16000, epochs=35, verbose=1, validation_split=0.2)\n",
        "score = model_cnn.evaluate(X_test, Y_test, verbose=1)\n",
        "scoretrain = model_cnn.evaluate(X_train, Y_train, verbose=1)\n",
        "print('Train Accuracy:', scoretrain[1])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/35\n",
            "32000/32000 [==============================] - 6s 196us/step - loss: 0.6992 - acc: 0.5012 - val_loss: 0.6951 - val_acc: 0.5000\n",
            "Epoch 2/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6938 - acc: 0.5012 - val_loss: 0.6920 - val_acc: 0.5000\n",
            "Epoch 3/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6912 - acc: 0.5328 - val_loss: 0.6910 - val_acc: 0.5006\n",
            "Epoch 4/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6904 - acc: 0.4992 - val_loss: 0.6904 - val_acc: 0.5002\n",
            "Epoch 5/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6894 - acc: 0.4988 - val_loss: 0.6887 - val_acc: 0.5001\n",
            "Epoch 6/35\n",
            "32000/32000 [==============================] - 1s 39us/step - loss: 0.6872 - acc: 0.4992 - val_loss: 0.6857 - val_acc: 0.5073\n",
            "Epoch 7/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6839 - acc: 0.5343 - val_loss: 0.6821 - val_acc: 0.6649\n",
            "Epoch 8/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6800 - acc: 0.7195 - val_loss: 0.6778 - val_acc: 0.7500\n",
            "Epoch 9/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6752 - acc: 0.7562 - val_loss: 0.6722 - val_acc: 0.7239\n",
            "Epoch 10/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6688 - acc: 0.7364 - val_loss: 0.6644 - val_acc: 0.7354\n",
            "Epoch 11/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6601 - acc: 0.7507 - val_loss: 0.6539 - val_acc: 0.7571\n",
            "Epoch 12/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6485 - acc: 0.7725 - val_loss: 0.6404 - val_acc: 0.7640\n",
            "Epoch 13/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.6337 - acc: 0.7787 - val_loss: 0.6239 - val_acc: 0.7665\n",
            "Epoch 14/35\n",
            "32000/32000 [==============================] - 1s 39us/step - loss: 0.6154 - acc: 0.7806 - val_loss: 0.6040 - val_acc: 0.7716\n",
            "Epoch 15/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.5933 - acc: 0.7857 - val_loss: 0.5811 - val_acc: 0.7722\n",
            "Epoch 16/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.5679 - acc: 0.7906 - val_loss: 0.5562 - val_acc: 0.7825\n",
            "Epoch 17/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.5400 - acc: 0.7963 - val_loss: 0.5305 - val_acc: 0.7883\n",
            "Epoch 18/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.5107 - acc: 0.8035 - val_loss: 0.5057 - val_acc: 0.7933\n",
            "Epoch 19/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.4818 - acc: 0.8118 - val_loss: 0.4828 - val_acc: 0.7965\n",
            "Epoch 20/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.4544 - acc: 0.8208 - val_loss: 0.4627 - val_acc: 0.8008\n",
            "Epoch 21/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.4293 - acc: 0.8287 - val_loss: 0.4458 - val_acc: 0.8086\n",
            "Epoch 22/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.4067 - acc: 0.8374 - val_loss: 0.4318 - val_acc: 0.8145\n",
            "Epoch 23/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.3863 - acc: 0.8465 - val_loss: 0.4207 - val_acc: 0.8177\n",
            "Epoch 24/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.3686 - acc: 0.8552 - val_loss: 0.4123 - val_acc: 0.8198\n",
            "Epoch 25/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.3528 - acc: 0.8612 - val_loss: 0.4060 - val_acc: 0.8230\n",
            "Epoch 26/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.3390 - acc: 0.8682 - val_loss: 0.4016 - val_acc: 0.8248\n",
            "Epoch 27/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.3267 - acc: 0.8743 - val_loss: 0.3987 - val_acc: 0.8234\n",
            "Epoch 28/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.3155 - acc: 0.8803 - val_loss: 0.3972 - val_acc: 0.8248\n",
            "Epoch 29/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.3053 - acc: 0.8856 - val_loss: 0.3969 - val_acc: 0.8259\n",
            "Epoch 30/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.2958 - acc: 0.8910 - val_loss: 0.3973 - val_acc: 0.8267\n",
            "Epoch 31/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.2869 - acc: 0.8963 - val_loss: 0.3983 - val_acc: 0.8276\n",
            "Epoch 32/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.2786 - acc: 0.9014 - val_loss: 0.3998 - val_acc: 0.8253\n",
            "Epoch 33/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.2707 - acc: 0.9064 - val_loss: 0.4015 - val_acc: 0.8242\n",
            "Epoch 34/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.2632 - acc: 0.9113 - val_loss: 0.4033 - val_acc: 0.8248\n",
            "Epoch 35/35\n",
            "32000/32000 [==============================] - 1s 38us/step - loss: 0.2562 - acc: 0.9157 - val_loss: 0.4056 - val_acc: 0.8227\n",
            "10000/10000 [==============================] - 0s 41us/step\n",
            "40000/40000 [==============================] - 2s 41us/step\n",
            "Train Accuracy: 0.900025\n",
            "Test Accuracy: 0.8242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEZjStooh3qv",
        "colab_type": "text"
      },
      "source": [
        "CNN + GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uQQj3kxh3KV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "08ac886e-3799-4f9f-fe19-9558ab8e81c6"
      },
      "source": [
        "model_cnn_glove = Sequential()\n",
        "embedding_layer = Embedding(vocabsize, 100, weights=[embedding_matrix], input_length=maxlength, trainable=False)\n",
        "model_cnn_glove.add(embedding_layer)\n",
        "model_cnn_glove.add(Conv1D(512, 5, activation='relu'))\n",
        "model_cnn_glove.add(GlobalMaxPooling1D())\n",
        "model_cnn_glove.add(Dense(16, activation='sigmoid'))\n",
        "model_cnn_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_cnn_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model_cnn_glove.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 100)          9254700   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 96, 512)           256512    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                8208      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 9,519,437\n",
            "Trainable params: 264,737\n",
            "Non-trainable params: 9,254,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZuz-BZfh8vb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c62bdd4-eba3-4f54-ad1f-91bcd864bafe"
      },
      "source": [
        "history_cnn_glove = model_cnn_glove.fit(X_train, Y_train, batch_size=16000, epochs=150, verbose=1, validation_split=0.2)\n",
        "score = model_cnn_glove.evaluate(X_test, Y_test, verbose=1)\n",
        "scoretrain = model_cnn_glove.evaluate(X_train, Y_train, verbose=1)\n",
        "print('Train Accuracy:', scoretrain[1])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/150\n",
            "32000/32000 [==============================] - 1s 44us/step - loss: 0.7339 - acc: 0.5088 - val_loss: 0.7236 - val_acc: 0.5000\n",
            "Epoch 2/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.7256 - acc: 0.5012 - val_loss: 0.7098 - val_acc: 0.5000\n",
            "Epoch 3/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6984 - acc: 0.5020 - val_loss: 0.6814 - val_acc: 0.6346\n",
            "Epoch 4/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6836 - acc: 0.5664 - val_loss: 0.6896 - val_acc: 0.5000\n",
            "Epoch 5/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6894 - acc: 0.4988 - val_loss: 0.6860 - val_acc: 0.5001\n",
            "Epoch 6/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6832 - acc: 0.5018 - val_loss: 0.6740 - val_acc: 0.5750\n",
            "Epoch 7/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6703 - acc: 0.6344 - val_loss: 0.6651 - val_acc: 0.6460\n",
            "Epoch 8/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6641 - acc: 0.6191 - val_loss: 0.6622 - val_acc: 0.5987\n",
            "Epoch 9/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6570 - acc: 0.6326 - val_loss: 0.6477 - val_acc: 0.7003\n",
            "Epoch 10/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6469 - acc: 0.6870 - val_loss: 0.6477 - val_acc: 0.6406\n",
            "Epoch 11/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6453 - acc: 0.6484 - val_loss: 0.6374 - val_acc: 0.6930\n",
            "Epoch 12/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6334 - acc: 0.7047 - val_loss: 0.6293 - val_acc: 0.7076\n",
            "Epoch 13/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6271 - acc: 0.7086 - val_loss: 0.6235 - val_acc: 0.7117\n",
            "Epoch 14/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6197 - acc: 0.7201 - val_loss: 0.6142 - val_acc: 0.7200\n",
            "Epoch 15/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6115 - acc: 0.7224 - val_loss: 0.6074 - val_acc: 0.7165\n",
            "Epoch 16/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.6036 - acc: 0.7263 - val_loss: 0.5978 - val_acc: 0.7334\n",
            "Epoch 17/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5946 - acc: 0.7440 - val_loss: 0.5904 - val_acc: 0.7425\n",
            "Epoch 18/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5859 - acc: 0.7502 - val_loss: 0.5799 - val_acc: 0.7460\n",
            "Epoch 19/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5764 - acc: 0.7545 - val_loss: 0.5722 - val_acc: 0.7495\n",
            "Epoch 20/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5678 - acc: 0.7608 - val_loss: 0.5622 - val_acc: 0.7613\n",
            "Epoch 21/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5581 - acc: 0.7693 - val_loss: 0.5534 - val_acc: 0.7688\n",
            "Epoch 22/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5490 - acc: 0.7756 - val_loss: 0.5442 - val_acc: 0.7713\n",
            "Epoch 23/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5400 - acc: 0.7777 - val_loss: 0.5347 - val_acc: 0.7781\n",
            "Epoch 24/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5302 - acc: 0.7833 - val_loss: 0.5258 - val_acc: 0.7847\n",
            "Epoch 25/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5215 - acc: 0.7891 - val_loss: 0.5169 - val_acc: 0.7895\n",
            "Epoch 26/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5129 - acc: 0.7914 - val_loss: 0.5089 - val_acc: 0.7914\n",
            "Epoch 27/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.5047 - acc: 0.7940 - val_loss: 0.5009 - val_acc: 0.7972\n",
            "Epoch 28/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4968 - acc: 0.7984 - val_loss: 0.4933 - val_acc: 0.7994\n",
            "Epoch 29/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4892 - acc: 0.8015 - val_loss: 0.4863 - val_acc: 0.8009\n",
            "Epoch 30/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4820 - acc: 0.8044 - val_loss: 0.4797 - val_acc: 0.8026\n",
            "Epoch 31/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4751 - acc: 0.8080 - val_loss: 0.4733 - val_acc: 0.8060\n",
            "Epoch 32/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4686 - acc: 0.8100 - val_loss: 0.4676 - val_acc: 0.8087\n",
            "Epoch 33/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4624 - acc: 0.8129 - val_loss: 0.4623 - val_acc: 0.8089\n",
            "Epoch 34/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4565 - acc: 0.8154 - val_loss: 0.4571 - val_acc: 0.8112\n",
            "Epoch 35/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4507 - acc: 0.8173 - val_loss: 0.4523 - val_acc: 0.8124\n",
            "Epoch 36/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4455 - acc: 0.8204 - val_loss: 0.4479 - val_acc: 0.8141\n",
            "Epoch 37/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4403 - acc: 0.8227 - val_loss: 0.4438 - val_acc: 0.8151\n",
            "Epoch 38/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4351 - acc: 0.8254 - val_loss: 0.4401 - val_acc: 0.8159\n",
            "Epoch 39/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4304 - acc: 0.8275 - val_loss: 0.4367 - val_acc: 0.8189\n",
            "Epoch 40/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4259 - acc: 0.8307 - val_loss: 0.4331 - val_acc: 0.8189\n",
            "Epoch 41/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4213 - acc: 0.8345 - val_loss: 0.4297 - val_acc: 0.8201\n",
            "Epoch 42/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4168 - acc: 0.8363 - val_loss: 0.4267 - val_acc: 0.8220\n",
            "Epoch 43/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4124 - acc: 0.8391 - val_loss: 0.4238 - val_acc: 0.8232\n",
            "Epoch 44/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4082 - acc: 0.8416 - val_loss: 0.4210 - val_acc: 0.8244\n",
            "Epoch 45/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4040 - acc: 0.8443 - val_loss: 0.4184 - val_acc: 0.8257\n",
            "Epoch 46/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.4000 - acc: 0.8467 - val_loss: 0.4158 - val_acc: 0.8257\n",
            "Epoch 47/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3959 - acc: 0.8492 - val_loss: 0.4134 - val_acc: 0.8276\n",
            "Epoch 48/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3918 - acc: 0.8510 - val_loss: 0.4110 - val_acc: 0.8288\n",
            "Epoch 49/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3880 - acc: 0.8534 - val_loss: 0.4092 - val_acc: 0.8290\n",
            "Epoch 50/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3841 - acc: 0.8546 - val_loss: 0.4071 - val_acc: 0.8317\n",
            "Epoch 51/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3807 - acc: 0.8572 - val_loss: 0.4042 - val_acc: 0.8330\n",
            "Epoch 52/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3760 - acc: 0.8601 - val_loss: 0.4019 - val_acc: 0.8350\n",
            "Epoch 53/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3718 - acc: 0.8623 - val_loss: 0.3994 - val_acc: 0.8359\n",
            "Epoch 54/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3675 - acc: 0.8643 - val_loss: 0.3970 - val_acc: 0.8366\n",
            "Epoch 55/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3628 - acc: 0.8665 - val_loss: 0.3926 - val_acc: 0.8364\n",
            "Epoch 56/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3570 - acc: 0.8692 - val_loss: 0.3898 - val_acc: 0.8366\n",
            "Epoch 57/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3523 - acc: 0.8707 - val_loss: 0.3891 - val_acc: 0.8374\n",
            "Epoch 58/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3493 - acc: 0.8730 - val_loss: 0.3863 - val_acc: 0.8370\n",
            "Epoch 59/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3458 - acc: 0.8757 - val_loss: 0.3839 - val_acc: 0.8406\n",
            "Epoch 60/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3421 - acc: 0.8764 - val_loss: 0.3852 - val_acc: 0.8385\n",
            "Epoch 61/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3390 - acc: 0.8794 - val_loss: 0.3832 - val_acc: 0.8380\n",
            "Epoch 62/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3373 - acc: 0.8790 - val_loss: 0.3792 - val_acc: 0.8406\n",
            "Epoch 63/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3318 - acc: 0.8836 - val_loss: 0.3798 - val_acc: 0.8409\n",
            "Epoch 64/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3284 - acc: 0.8858 - val_loss: 0.3779 - val_acc: 0.8405\n",
            "Epoch 65/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3245 - acc: 0.8872 - val_loss: 0.3761 - val_acc: 0.8424\n",
            "Epoch 66/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3228 - acc: 0.8885 - val_loss: 0.3741 - val_acc: 0.8425\n",
            "Epoch 67/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3181 - acc: 0.8931 - val_loss: 0.3765 - val_acc: 0.8405\n",
            "Epoch 68/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3172 - acc: 0.8903 - val_loss: 0.3714 - val_acc: 0.8444\n",
            "Epoch 69/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3119 - acc: 0.8955 - val_loss: 0.3710 - val_acc: 0.8428\n",
            "Epoch 70/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3081 - acc: 0.8984 - val_loss: 0.3697 - val_acc: 0.8441\n",
            "Epoch 71/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3046 - acc: 0.9000 - val_loss: 0.3679 - val_acc: 0.8445\n",
            "Epoch 72/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.3011 - acc: 0.9023 - val_loss: 0.3668 - val_acc: 0.8446\n",
            "Epoch 73/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2978 - acc: 0.9047 - val_loss: 0.3661 - val_acc: 0.8450\n",
            "Epoch 74/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2946 - acc: 0.9066 - val_loss: 0.3648 - val_acc: 0.8447\n",
            "Epoch 75/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2913 - acc: 0.9077 - val_loss: 0.3637 - val_acc: 0.8457\n",
            "Epoch 76/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2879 - acc: 0.9102 - val_loss: 0.3632 - val_acc: 0.8462\n",
            "Epoch 77/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2850 - acc: 0.9113 - val_loss: 0.3623 - val_acc: 0.8469\n",
            "Epoch 78/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2814 - acc: 0.9135 - val_loss: 0.3607 - val_acc: 0.8449\n",
            "Epoch 79/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2782 - acc: 0.9153 - val_loss: 0.3605 - val_acc: 0.8462\n",
            "Epoch 80/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2766 - acc: 0.9155 - val_loss: 0.3637 - val_acc: 0.8447\n",
            "Epoch 81/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2793 - acc: 0.9120 - val_loss: 0.3653 - val_acc: 0.8428\n",
            "Epoch 82/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2745 - acc: 0.9152 - val_loss: 0.3573 - val_acc: 0.8466\n",
            "Epoch 83/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2666 - acc: 0.9225 - val_loss: 0.3628 - val_acc: 0.8480\n",
            "Epoch 84/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2667 - acc: 0.9190 - val_loss: 0.3561 - val_acc: 0.8484\n",
            "Epoch 85/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2597 - acc: 0.9243 - val_loss: 0.3570 - val_acc: 0.8466\n",
            "Epoch 86/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2578 - acc: 0.9266 - val_loss: 0.3548 - val_acc: 0.8490\n",
            "Epoch 87/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2547 - acc: 0.9287 - val_loss: 0.3589 - val_acc: 0.8487\n",
            "Epoch 88/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2544 - acc: 0.9277 - val_loss: 0.3545 - val_acc: 0.8494\n",
            "Epoch 89/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2480 - acc: 0.9309 - val_loss: 0.3526 - val_acc: 0.8482\n",
            "Epoch 90/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2444 - acc: 0.9345 - val_loss: 0.3519 - val_acc: 0.8481\n",
            "Epoch 91/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2417 - acc: 0.9358 - val_loss: 0.3521 - val_acc: 0.8480\n",
            "Epoch 92/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2411 - acc: 0.9350 - val_loss: 0.3539 - val_acc: 0.8471\n",
            "Epoch 93/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2398 - acc: 0.9348 - val_loss: 0.3507 - val_acc: 0.8486\n",
            "Epoch 94/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2330 - acc: 0.9408 - val_loss: 0.3511 - val_acc: 0.8504\n",
            "Epoch 95/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2322 - acc: 0.9402 - val_loss: 0.3622 - val_acc: 0.8482\n",
            "Epoch 96/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2357 - acc: 0.9349 - val_loss: 0.3519 - val_acc: 0.8512\n",
            "Epoch 97/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2246 - acc: 0.9432 - val_loss: 0.3494 - val_acc: 0.8484\n",
            "Epoch 98/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2230 - acc: 0.9454 - val_loss: 0.3477 - val_acc: 0.8494\n",
            "Epoch 99/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2181 - acc: 0.9472 - val_loss: 0.3503 - val_acc: 0.8504\n",
            "Epoch 100/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2164 - acc: 0.9479 - val_loss: 0.3475 - val_acc: 0.8506\n",
            "Epoch 101/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2123 - acc: 0.9499 - val_loss: 0.3462 - val_acc: 0.8494\n",
            "Epoch 102/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2104 - acc: 0.9506 - val_loss: 0.3473 - val_acc: 0.8484\n",
            "Epoch 103/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2109 - acc: 0.9490 - val_loss: 0.3496 - val_acc: 0.8490\n",
            "Epoch 104/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2104 - acc: 0.9486 - val_loss: 0.3465 - val_acc: 0.8489\n",
            "Epoch 105/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2025 - acc: 0.9548 - val_loss: 0.3478 - val_acc: 0.8512\n",
            "Epoch 106/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2016 - acc: 0.9543 - val_loss: 0.3550 - val_acc: 0.8503\n",
            "Epoch 107/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.2011 - acc: 0.9526 - val_loss: 0.3456 - val_acc: 0.8506\n",
            "Epoch 108/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1938 - acc: 0.9583 - val_loss: 0.3480 - val_acc: 0.8494\n",
            "Epoch 109/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1996 - acc: 0.9525 - val_loss: 0.3477 - val_acc: 0.8493\n",
            "Epoch 110/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1914 - acc: 0.9591 - val_loss: 0.3494 - val_acc: 0.8519\n",
            "Epoch 111/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1932 - acc: 0.9557 - val_loss: 0.3573 - val_acc: 0.8486\n",
            "Epoch 112/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1889 - acc: 0.9579 - val_loss: 0.3429 - val_acc: 0.8503\n",
            "Epoch 113/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1864 - acc: 0.9593 - val_loss: 0.3514 - val_acc: 0.8453\n",
            "Epoch 114/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1862 - acc: 0.9584 - val_loss: 0.3465 - val_acc: 0.8515\n",
            "Epoch 115/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1831 - acc: 0.9607 - val_loss: 0.3556 - val_acc: 0.8494\n",
            "Epoch 116/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1784 - acc: 0.9636 - val_loss: 0.3438 - val_acc: 0.8501\n",
            "Epoch 117/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1761 - acc: 0.9642 - val_loss: 0.3418 - val_acc: 0.8516\n",
            "Epoch 118/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1705 - acc: 0.9690 - val_loss: 0.3489 - val_acc: 0.8525\n",
            "Epoch 119/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1690 - acc: 0.9688 - val_loss: 0.3422 - val_acc: 0.8504\n",
            "Epoch 120/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1687 - acc: 0.9679 - val_loss: 0.3420 - val_acc: 0.8503\n",
            "Epoch 121/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1641 - acc: 0.9714 - val_loss: 0.3487 - val_acc: 0.8519\n",
            "Epoch 122/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1650 - acc: 0.9698 - val_loss: 0.3436 - val_acc: 0.8516\n",
            "Epoch 123/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1595 - acc: 0.9737 - val_loss: 0.3425 - val_acc: 0.8508\n",
            "Epoch 124/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1595 - acc: 0.9732 - val_loss: 0.3414 - val_acc: 0.8516\n",
            "Epoch 125/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1561 - acc: 0.9748 - val_loss: 0.3521 - val_acc: 0.8494\n",
            "Epoch 126/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1574 - acc: 0.9723 - val_loss: 0.3415 - val_acc: 0.8511\n",
            "Epoch 127/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1524 - acc: 0.9756 - val_loss: 0.3451 - val_acc: 0.8491\n",
            "Epoch 128/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1540 - acc: 0.9737 - val_loss: 0.3417 - val_acc: 0.8518\n",
            "Epoch 129/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1490 - acc: 0.9770 - val_loss: 0.3541 - val_acc: 0.8482\n",
            "Epoch 130/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1489 - acc: 0.9759 - val_loss: 0.3410 - val_acc: 0.8521\n",
            "Epoch 131/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1488 - acc: 0.9758 - val_loss: 0.3467 - val_acc: 0.8482\n",
            "Epoch 132/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1464 - acc: 0.9770 - val_loss: 0.3466 - val_acc: 0.8519\n",
            "Epoch 133/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1440 - acc: 0.9773 - val_loss: 0.3483 - val_acc: 0.8509\n",
            "Epoch 134/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1391 - acc: 0.9796 - val_loss: 0.3429 - val_acc: 0.8504\n",
            "Epoch 135/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1401 - acc: 0.9795 - val_loss: 0.3408 - val_acc: 0.8510\n",
            "Epoch 136/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1348 - acc: 0.9818 - val_loss: 0.3510 - val_acc: 0.8496\n",
            "Epoch 137/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1359 - acc: 0.9801 - val_loss: 0.3414 - val_acc: 0.8506\n",
            "Epoch 138/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1308 - acc: 0.9831 - val_loss: 0.3410 - val_acc: 0.8515\n",
            "Epoch 139/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1292 - acc: 0.9832 - val_loss: 0.3431 - val_acc: 0.8516\n",
            "Epoch 140/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1277 - acc: 0.9838 - val_loss: 0.3445 - val_acc: 0.8509\n",
            "Epoch 141/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1255 - acc: 0.9846 - val_loss: 0.3411 - val_acc: 0.8506\n",
            "Epoch 142/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1253 - acc: 0.9847 - val_loss: 0.3414 - val_acc: 0.8522\n",
            "Epoch 143/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1225 - acc: 0.9852 - val_loss: 0.3456 - val_acc: 0.8512\n",
            "Epoch 144/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1212 - acc: 0.9855 - val_loss: 0.3422 - val_acc: 0.8508\n",
            "Epoch 145/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1189 - acc: 0.9868 - val_loss: 0.3417 - val_acc: 0.8519\n",
            "Epoch 146/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1181 - acc: 0.9868 - val_loss: 0.3419 - val_acc: 0.8503\n",
            "Epoch 147/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1155 - acc: 0.9872 - val_loss: 0.3466 - val_acc: 0.8508\n",
            "Epoch 148/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1145 - acc: 0.9874 - val_loss: 0.3419 - val_acc: 0.8499\n",
            "Epoch 149/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1130 - acc: 0.9881 - val_loss: 0.3423 - val_acc: 0.8519\n",
            "Epoch 150/150\n",
            "32000/32000 [==============================] - 1s 32us/step - loss: 0.1121 - acc: 0.9881 - val_loss: 0.3422 - val_acc: 0.8501\n",
            "10000/10000 [==============================] - 0s 41us/step\n",
            "40000/40000 [==============================] - 2s 41us/step\n",
            "Train Accuracy: 0.960975\n",
            "Test Accuracy: 0.8556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy1JqJO1-VPl",
        "colab_type": "text"
      },
      "source": [
        "Model \n",
        "Pickling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-83zzm-Tax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2aec1379-4a43-4360-d5c1-067fefb10e2c"
      },
      "source": [
        "m1 = 'mlp' + '.joblib'\n",
        "m2 = 'mlp_glove' + '.joblib'\n",
        "m3 = 'cnn' + '.joblib'\n",
        "m4 = 'cnn_glove' + '.joblib'\n",
        "h1 = 'history_mlp' + '.joblib'\n",
        "h2 = 'history_mlp_glove' + '.joblib'\n",
        "h3 = 'history_cnn' + '.joblib'\n",
        "h4 = 'history_cnn_glove' + '.joblib'\n",
        "\n",
        "joblib.dump(model_mlp, m1)\n",
        "joblib.dump(model_mlp_glove, m2)\n",
        "joblib.dump(model_cnn, m3)\n",
        "joblib.dump(model_cnn_glove, m4)\n",
        "joblib.dump(history_mlp, h1)\n",
        "joblib.dump(history_mlp_glove, h2)\n",
        "joblib.dump(history_cnn, h3)\n",
        "joblib.dump(history_cnn_glove, h4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['history_cnn_glove.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArVlJPBKG6ZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)  \n",
        "\n",
        "# get the folder id where you want to save your file\n",
        "file = drive.CreateFile({'parents':[{u'id': '1rmTGbb19iJn6VbHoHdTYQbK0m0V_EQvP'}]})\n",
        "file.SetContentFile(m1)\n",
        "file.Upload() \n",
        "\n",
        "file = drive.CreateFile({'parents':[{u'id': '1rmTGbb19iJn6VbHoHdTYQbK0m0V_EQvP'}]})\n",
        "file.SetContentFile(m2)\n",
        "file.Upload() \n",
        "\n",
        "file = drive.CreateFile({'parents':[{u'id': '1rmTGbb19iJn6VbHoHdTYQbK0m0V_EQvP'}]})\n",
        "file.SetContentFile(m3)\n",
        "file.Upload() \n",
        "\n",
        "file = drive.CreateFile({'parents':[{u'id': '1rmTGbb19iJn6VbHoHdTYQbK0m0V_EQvP'}]})\n",
        "file.SetContentFile(m4)\n",
        "file.Upload() \n",
        "\n",
        "file = drive.CreateFile({'parents':[{u'id': '1rmTGbb19iJn6VbHoHdTYQbK0m0V_EQvP'}]})\n",
        "file.SetContentFile(h1)\n",
        "file.Upload() \n",
        "\n",
        "file = drive.CreateFile({'parents':[{u'id': '1rmTGbb19iJn6VbHoHdTYQbK0m0V_EQvP'}]})\n",
        "file.SetContentFile(h2)\n",
        "file.Upload()\n",
        "\n",
        "file = drive.CreateFile({'parents':[{u'id': '1rmTGbb19iJn6VbHoHdTYQbK0m0V_EQvP'}]})\n",
        "file.SetContentFile(h3)\n",
        "file.Upload()\n",
        "\n",
        "file = drive.CreateFile({'parents':[{u'id': '1rmTGbb19iJn6VbHoHdTYQbK0m0V_EQvP'}]})\n",
        "file.SetContentFile(h4)\n",
        "file.Upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMSEWDR-F6Lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_mlp = joblib.load('/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/' + m1)\n",
        "# model_mlp_glove = joblib.load('/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/' + m2)\n",
        "# model_cnn = joblib.load('/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/' + m3)\n",
        "# model_cnn_glove = joblib.load('/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/' + m4)\n",
        "# history_mlp = joblib.load('/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/' + h1)\n",
        "# history_mlp_glove = joblib.load('/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/' + h2)\n",
        "# history_cnn = joblib.load('/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/' + h3)\n",
        "# history_cnn_glove = joblib.load('/content/drive/My Drive/DATASET FOR ML ASSIGNMENT/' + h4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOji_HLPqSla",
        "colab_type": "text"
      },
      "source": [
        "# Plotting the Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKFwsLn2qWOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r268kDYzrowx",
        "colab_type": "text"
      },
      "source": [
        "NN + Self Trained Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRYnJH6Irnur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(list(range(1, 101)), history_mlp.history['val_loss'], color='green', label='Validation Loss')\n",
        "plt.plot(list(range(1, 101)), history_mlp.history['loss'], color='brown', label='Training Loss')\n",
        "plt.plot(list(range(1, 101)), history_mlp.history['val_acc'], color='indigo', label='Validation Accuracy')\n",
        "plt.plot(list(range(1, 101)), history_mlp.history['acc'], color='orange', label='Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.title('Model Loss & Accuracy (NN with Self Training Embedding Layer)')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjmiMf8VtPek",
        "colab_type": "text"
      },
      "source": [
        "NN + GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlshGak-tRe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(list(range(1, 251)), history_mlp_glove.history['val_loss'], color='green', label='Validation Loss')\n",
        "plt.plot(list(range(1, 251)), history_mlp_glove.history['loss'], color='brown', label='Training Loss')\n",
        "plt.plot(list(range(1, 251)), history_mlp_glove.history['val_acc'], color='indigo', label='Validation Accuracy')\n",
        "plt.plot(list(range(1, 251)), history_mlp_glove.history['acc'], color='orange', label='Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.title('Model Loss & Accuracy (NN with GloVe Embedding Layer)')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT6uoe2ttrwp",
        "colab_type": "text"
      },
      "source": [
        "CNN + Self Trained Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXGRU46NtrT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(list(range(1, 36)), history_cnn.history['val_loss'], color='green', label='Validation Loss')\n",
        "plt.plot(list(range(1, 36)), history_cnn.history['loss'], color='brown', label='Training Loss')\n",
        "plt.plot(list(range(1, 36)), history_cnn.history['val_acc'], color='indigo', label='Validation Accuracy')\n",
        "plt.plot(list(range(1, 36)), history_cnn.history['acc'], color='orange', label='Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.title('Model Loss & Accuracy (CNN with Self Training Embedding Layer)')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPgkYkrzt8BU",
        "colab_type": "text"
      },
      "source": [
        "CNN + GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9uoeCjpt9bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(list(range(1, 151)), history_cnn_glove.history['val_loss'], color='green', label='Validation Loss')\n",
        "plt.plot(list(range(1, 151)), history_cnn_glove.history['loss'], color='brown', label='Training Loss')\n",
        "plt.plot(list(range(1, 151)), history_cnn_glove.history['val_acc'], color='indigo', label='Validation Accuracy')\n",
        "plt.plot(list(range(1, 151)), history_cnn_glove.history['acc'], color='orange', label='Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.title('Model Loss & Accuracy (CNN with GloVe Embedding Layer)')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}